{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historische Simulation versus Varianz-Kovarianz-Methode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Thomas Robert Holy 2019\n",
    "<br>\n",
    "Version 1.0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voraussetzungen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An dieser Stelle ist bereits alles vorbereitet.\n",
    "Das Notebook lässt sich bereits vollständig mit fiktiven Aktienkursen ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein Portfolio mit echten Aktienkursen zusammenzustellen, können im Home-Verzeichnis bis zu fünf .csv-Datein hochgeladen werden. Diese müssen die folgenden Kriterien erfüllen:\n",
    "<br>\n",
    "- Sie umfassen alle denselben Zeitraum\n",
    "<br>\n",
    "- Es wird ein Punkt zur Dezimaltrennung verwendet\n",
    "<br>\n",
    "- Es wird ein Komma zur Spaltentrennung verwendet\n",
    "\n",
    "<br>\n",
    "Abrufbar sind die Daten z.B. auf Yahoo Finance: https://de.finance.yahoo.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlegende Einstellungen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst müssen die notwendigen Pakete (auch Module) importiert werden, damit auf diese zugegriffen werden kann. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Programmbibliothek die eine einfache Handhabung von Vektoren, Matrizen oder generell großen mehrdimensionalen Arrays ermöglicht\n",
    "import pandas as pd # Programmbibliothek die Hilfsmittel für die Verwaltung von Daten und deren Analyse anbietet\n",
    "import matplotlib.pyplot as plt # Programmbibliothek die es erlaubt mathematische Darstellungen aller Art anzufertigen\n",
    "import matplotlib.patches as mpatches\n",
    "import operator # Programmbibliothek, welche die Ausgaben übersichtlicher gestaltet\n",
    "import datetime as dt # Das datetime-Modul stellt Klassen bereit, mit denen Datums- und Uhrzeitangaben auf einfache und komplexe Weise bearbeitet werden können\n",
    "import sys # Dieses Modul bietet Zugriff auf einige Variablen, die vom Interpreter verwendet oder verwaltet werden, sowie auf Funktionen, die stark mit dem Interpreter interagieren\n",
    "from scipy import stats # SciPy ist ein Python-basiertes Ökosystem für Open-Source-Software für Mathematik, Naturwissenschaften und Ingenieurwissenschaften"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden Einstellungen definiert, die die Formatierung der Ausgaben betreffen.\n",
    "Hierfür wird das Modul `operator` genutzt.\n",
    "Außerdem wird die Breite des im Folgenden genutzten DataFrames erhöht und die Größe der Grafiken modifiziert, welche später angezeigt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "SCREEN_WIDTH = 140\n",
    "centered = operator.methodcaller('center', SCREEN_WIDTH)\n",
    "\n",
    "pd.set_option('display.width', 125)\n",
    "plt.rcParams[\"figure.figsize\"] = 15,12.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Beispiel für die Ausgabe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Die Ausgabe wird nun zentriert um die Übersichtlichkeit zu verbessern.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensätze einlesen und manipulieren:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden Datensätze eingelesen.\n",
    "Da Jupyter Notebook leider Eingaben nicht zeilenweise einlesen kann, müssen die Datensätze manuell definiert und anschließend zum Array \"dateinamen\" hinzufügt werden.\n",
    "Standardmäßig werden zunächst zwei Datensätze (example1, example2) definiert und im Array \"dateinamen\" gespeichert.\n",
    "<br><br>\n",
    "Hinweis: An dieser Stelle können alternativ \"richtige\" Datensätze eingelesen werden, indem \"example1\" z.B. in BAS.DE und \"example2\" z.B. in VOW3.DE umbenannt werden, sofern die entsprechenden Datensätze im Home-Verzeichnis hochgeladen wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "datensatz1 = 'example1'\n",
    "datensatz2 = 'example2'\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Hier können weitere Datensätze definiert werden.\n",
    "\n",
    "#datensatz3 = ''\n",
    "#datensatz4 = ''\n",
    "#datensatz5 = ''\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Diese müssen ggf. noch in diesem Array ergänzt werden.\n",
    "\n",
    "dateinamen = [datensatz1,datensatz2]\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt soll aus jedem eingelesen Datensatz der Aktienkurs zum jeweiligen Tag extrahiert werden. \n",
    "Diesen Schritt kann man in Python automatisieren, indem zunächst die leere Liste \"kurse\" anlegt wird und anschließend für jeden Eintrag in der Liste \"dateinamen\" die jeweiligen Spalten \"Date\" und \"Adj Close\" eingelesen werden.\n",
    "Dabei werden die verschiedenen im Datensatz vorhanden Spalten mit jedem Komma separiert und Punkte werden als Zeichen für die Dezimaltrennung interpretiert. Anschließend werden die so extrahierten Daten zum Array \"kurse\" hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurse = []        \n",
    "\n",
    "for eintrag in dateinamen:\n",
    "    kurs = pd.read_csv(str(eintrag) + '.csv',\n",
    "                sep=',',\n",
    "                decimal='.',\n",
    "                usecols=['Date','Adj Close'])\n",
    "    kurse.append(kurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird das Modul `datetime` genutzt, um die Datumsspalte des jeweiligen Datensatzes bearbeitbar zu machen.\n",
    "Zudem wird dem Programm mitgeteilt, dass die Einträge der Spalte \"Adj Close\" numerisch sind und mit ihnen gerechnet werden kann. Kommt es dabei zu Fehlern werden die entsprechende Werte als NaN-Werte behandelt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eintrag in kurse:\n",
    "    eintrag['Date'] = pd.to_datetime(eintrag['Date'])\n",
    "    eintrag['Adj Close'] = pd.to_numeric(eintrag['Adj Close'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe erzeugen und Daten zusammentragen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend werden die eingelesenen Daten in einem DataFrame zusammengetragen, wofür das Modul `Pandas` verwendet wird.\n",
    "Ein DataFrame kann ähnlich wie eine Excel-Tabelle verstanden werden.\n",
    "Dieser Vorgang kann automatisiert werden, damit die einzelnen Spalten nicht manuell hinzufügt werden müssen. \n",
    "Zunächst wird dafür der leere DataFrame \"kurschart\" angelegt. \n",
    "Als nächstes wird für jeden Eintrag in dem Array \"kurse\" zunächst der entsprechende Aktienkurs in den DataFrame überführt und anschließend wird die dazugehörige Rendite berechnet.\n",
    "Um Aktienkurse und dazugehörige Renditen auseinander halten zu können, werden die Dateinamen aus dem Array \"dateinamen\" als Tabellenkopf verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurschart = pd.DataFrame()\n",
    "zaehler = 0\n",
    "\n",
    "for eintrag in kurse:\n",
    "    x = dateinamen[zaehler]\n",
    "    kurschart['Aktienkurs ' + str(x)] = eintrag['Adj Close']\n",
    "    kurschart['Rendite ' + str(x)] = (eintrag['Adj Close'] - eintrag['Adj Close'].shift(periods=1)) / eintrag['Adj Close'].shift(periods=1) \n",
    "    zaehler += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Portfolio-Rendite zu ermitteln, wird jede zweite Spalte des DataFrames \"kurschart\" ausgewählt (dies sind die jeweiligen Rendite-Spalten) und in einem zweiten DataFrame (\"hilfs_dataframe\") abgespeichert. \n",
    "Anschließend werden die Spalten zeilenweise addiert und durch die Anzahl der Datensätze geteilt, welche sich im Array \"dateinamen\" befinden. Dies entspricht einer naiven Diversifikation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hilfs_dataframe = kurschart.iloc[:, 1::2]\n",
    "hilfs_dataframe['PF-Rendite'] = hilfs_dataframe.sum(axis = 1, skipna = True) / len(dateinamen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Portfolio-Rendite wird nun dem ursprünglichen DataFrame \"kurschart\" angefügt. \n",
    "Zudem erhält der DataFrame eine Datumsspalte, welche gleichzeitig als Index verwendet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurschart['Rendite-PF'] = hilfs_dataframe['PF-Rendite']\n",
    "\n",
    "kurschart['Datum'] = eintrag['Date']\n",
    "kurschart = kurschart.set_index('Datum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann das DataFrame ausgeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Das Dataframe mit den Aktienkursen der jeweiligen Datensätze und deren zugehörigen Rendite ergibt sich wie folgt: ') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print(kurschart)\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streudiagramm anzeigen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe eines Streudiagramms kann die gemeinsame Verteilung von zwei Datensätzen bzw. deren Abhängigkeitsstruktur betrachtet werden.\n",
    "Um ein solches Streudiagramm zu plotten wird zunächst den Datensatz \"x\" und den Datensatz \"y\" definiert. \n",
    "Anschließend werden die zugehörigen Renditen in einer Liste gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "# Hier können auch andere Datensätze definiert werden. Wenn vier Datensätze \n",
    "# eingelesen wurden, könnten bspw. auch die Datensätze dateinamen[2] und \n",
    "# dateinamen[3] betrachtet werden.\n",
    "# Hinweis: Die Aufzählung startet bei Null.\n",
    "\n",
    "x = dateinamen[0]\n",
    "y = dateinamen[1]\n",
    "\n",
    "values_datensatz1 = kurschart['Rendite ' + str(x)].values.tolist()\n",
    "values_datensatz2 = kurschart['Rendite ' + str(y)].values.tolist()\n",
    "\n",
    "values_datensatz1 = np.array(values_datensatz1)\n",
    "values_datensatz2 = np.array(values_datensatz2)\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann das Streudiagramm für die jeweiligen Aktienkurse geplottet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(values_datensatz1, values_datensatz2)\n",
    "plt.xlabel('Rendite des Datensatzes ' + str(datensatz1))\n",
    "plt.ylabel('Rendite des Datensatzes ' + str(datensatz2)) \n",
    "plt.title('Gemeinsame Verteilung der Datensätze ' + str(datensatz1) + ' und ' + str(datensatz2))\n",
    "def easy_plot():\n",
    "    plt.grid()\n",
    "    plt.axhline(0, color='black')\n",
    "    plt.axvline(0, color='black')\n",
    "    plt.show()\n",
    "easy_plot()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zugehörigen Erwartungswerte und Standardabweichungen können auch ausgegeben werden. Dafür müssen die Listen zunächst um NaN-Werte bereinigt werden. Anschließend wird das Modul `Numpy` genutzt, welches den Erwartungswert und die Standardabweichung berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_datensatz1 = values_datensatz1[np.logical_not(np.isnan(values_datensatz1))]\n",
    "values_datensatz2 = values_datensatz2[np.logical_not(np.isnan(values_datensatz2))]\n",
    "values_datensatz1 = values_datensatz1[values_datensatz1 != 0.0]\n",
    "values_datensatz2 = values_datensatz2[values_datensatz2 != 0.0]\n",
    "\n",
    "mu_datensatz1 = np.mean(values_datensatz1)\n",
    "mu_datensatz2 =  np.mean(values_datensatz2)\n",
    "\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Die erwartete Rendite des Datensatzes ' + str(datensatz1) + ' beträgt ' + str(mu_datensatz1) + '.') + '| ')\n",
    "print('|' + centered('[INFO] Die erwartete Rendite des Datensatzes ' + str(datensatz2) + ' beträgt ' + str(mu_datensatz2) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "std_dattensatz1 = np.std(values_datensatz1)\n",
    "std_dattensatz2 = np.std(values_datensatz2)\n",
    "\n",
    "print('|' + centered('[INFO] Der Datensatz ' + str(datensatz1) + ' hat eine Standardabweichung i.H.v. ' + str(std_dattensatz1) + '.') + '| ')\n",
    "print('|' + centered('[INFO] Der Datensatz ' + str(datensatz2) + ' hat eine Standardabweichung i.H.v. ' + str(std_dattensatz2) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio-Renditedaten bereinigen und analysieren:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da für die Simulationsverfahren fortan die Portfolio-Rendite benötigt wird, wird diese ebenfalls in einer Liste abgespeichert und um NaN-Werte bereinigt. Anschließend wird wiederum der Erwartungswert und die Standardabweichung berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_PF = kurschart['Rendite-PF'].values.tolist()\n",
    "values_PF = np.array(values_PF)\n",
    "values_PF = values_PF[np.logical_not(np.isnan(values_PF))]\n",
    "values_PF = values_PF[values_PF != 0.0]\n",
    "\n",
    "mu_PF = np.mean(values_PF)\n",
    "\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "print('|' + centered('[INFO] Die Porfolio-Rendite hat einen Erwartunswert i.H.v. ' + str(mu_PF) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "std_PF = np.std(values_PF)\n",
    "\n",
    "print('|' + centered('[INFO] Das Porfolio hat somit eine Standardabweichung i.H.v. ' + str(std_PF) + '.') + '| ')\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "mu = mu_PF\n",
    "sigma = std_PF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Intervall beider Simulationsverfahren zu begrenzen, wird der kleinste und größte Rendite-Wert der in der Liste \"values_PF\" zu finden ist ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_values_PF = min(values_PF)\n",
    "maxi_values_PF = max(values_PF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abfragefunktion definieren:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird eine Funktion definiert mit deren Hilfe die Feinheit der jeweiligen Verteilungsfunktion bestimmt werden kann.\n",
    "Standardmäßig wird die höchste Feinheit gewählt, d.h. jede einzelne Realisation wird einzeln erfasst, sodass die Verteilungsfunktion eine sehr hohe Genauigkeit aufweist.\n",
    "Dies muss jedoch nicht immer sinnvoll sein, weshalb mithilfe einer Abfrage auch andere Werte akzeptiert werden sollen.\n",
    "Im Grunde die Funktion ob eine Anpassung vorgenommen werden soll oder nicht und wenn ja, welche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abfrage():\n",
    "    abfrage = None\n",
    "    while abfrage not in ('Ja', 'Nein', 'ja', 'nein', 'j', 'n'):\n",
    "        abfrage = input('|' + centered('[EINGABE] Möchten Sie die Genauigkeit anpassen? Geben Sie \"Ja\" oder \"Nein\" ein: ') + '| ')        \n",
    "        if abfrage == 'Nein' or abfrage == 'nein' or abfrage == 'n':\n",
    "            return len(values_PF)\n",
    "        elif abfrage == 'Ja' or abfrage == 'ja' or abfrage == 'j':\n",
    "            return int(input('|' + centered('[EINGABE] Geben sie eine Zahl zwischen ' + str(round(len(values_PF)/10)) + ' und ' + str(len(values_PF)) + ' ein') + '| '))    \n",
    "        else:\n",
    "            print('|' + centered('[WARNUNG] Geben Sie \"Ja\" oder \"Nein\" ein! ') + '| ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verteilungsfunktionen definieren und plotten:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im letzten Schritt gilt es nun alle Informationen zusammenzutragen und die beiden Verteilungsfunktionen zu zeichnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "bins = abfrage()\n",
    "print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Historische Simulation\n",
    "\n",
    "H, X1 = np.histogram(values_PF, bins, density=True)\n",
    "dx = X1[1] - X1[0]\n",
    "F1 = np.cumsum(H) * dx\n",
    "plt.plot(X1[1:], F1)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Varianz-Kovarianz-Methode\n",
    "\n",
    "var_covar_range = np.linspace(mini_values_PF, maxi_values_PF, bins)\n",
    "plt.plot(var_covar_range, stats.norm.cdf(var_covar_range, mu, sigma))\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Restliche Einstellungen für die Grafik\n",
    "\n",
    "plt.xlabel('Rendite')\n",
    "plt.ylabel('Wahrscheinlichkeit')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Historische Simulation')\n",
    "orange_patch = mpatches.Patch(color='orange', label='Varianz-Kovarianzmethode')\n",
    "plt.legend(handles=[orange_patch, blue_patch])\n",
    "plt.title('Verteilungsfunktion: Historische Simulation versus Varianz-Kovarianz-Methode')\n",
    "easy_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risikomaße schätzen - Historische Simulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den Value at Risk für die historische Simulation zu bestimmen, werden die Portfolio-Realisationen zunächst der Größe nach sortiert, wobei dieser Schritt gleichzeitig der Ausgangspunkt für die Berechnung des Conditional Value at Risk ist.\n",
    "Anschließend wird das Alpha-Quantil der Verlustfunktion bestimmt, indem der Parameter \"alpha\" mit der Länge der Liste \"RM_list\" multipliziert wird. Der so ermittelte Wert gibt die Position in der Liste \"RM_list\" an, an welcher sich der Value at Risk zum Konfidenzniveau \"alpha\" befindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_list = sorted(values_PF)\n",
    "\n",
    "def VaR(alpha):\n",
    "    item = int((alpha * len(RM_list))) - 1\n",
    "    VaR = -(RM_list[item])\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Der VaR beträgt: ' + str(VaR) + '.') + '| ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Value at Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Conditional Value at Risk wird grundsätzlich wie der Value at Risk bestimmt, wobei hier jedoch der Mittelwert über alle Realisationen bis zum Alpha-Quantil gebildet wird. \n",
    "Daher wird hier nach der Positionsbestimmung die Liste \"CVaR_list\" mit denjenigen Realisationen aus der Liste \"RM_list\" gefüllt, welche den Bereich von der kleinsten Realisation bis zum Alpha-Quantil abdecken. \n",
    "Die Summe dieser Liste wird anschließend durch die Anzahl ihrer Elemente geteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVaR(alpha):\n",
    "    item = int((alpha * len(RM_list)))\n",
    "    CVaR_list = RM_list[0:item]\n",
    "    CVaR = -(np.sum(CVaR_list) / len(CVaR_list))\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Der CVaR beträgt: ' + str(CVaR) + '.') + '| ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power-Spektrales Risikomaß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Power-Spektrale Risikomaß ergibt sich der Erwartungswert aus dem Mittelwert der \"RM_list\" (der Mittelwert der Portfolio-Realisationen) und das Risiko ergibt sich aus dem Matrixprodukt der transponierten \"RM_list\" mit der \"subj_ws_list\", welche subjektive Wahrscheinlichkeiten beinhaltet.\n",
    "Die Elemente letzterer Liste werden berechnet, indem die Laufvariable jeder Realisation in der geordneten Statisitk \"RM_list\" (bei \"example1\" 1 bis 364) durch die Gesamtanzahl der Realisationen (bei \"example1\" 364) geteilt und dann mit \"gamma\" potenziert wird (daher heißt es Power-Spektrales Risikomaß).\n",
    "Dabei ist bei jeder Berechnung der jeweils vorher errechnete Wert zu subtrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(gamma):\n",
    "    EW = np.mean(RM_list)\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Power-Spektrales Risikomaß bei der historischen Simulation:') + '| ')\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Der Erwartungswert beträgt: ' + str(EW) + '.') + '| ')\n",
    "\n",
    "    subj_ws_list = []\n",
    "    counter1 = len(RM_list)\n",
    "    counter2 = len(RM_list)-1\n",
    "    for i in RM_list:\n",
    "        subj_ws = (np.power((counter1 / len(RM_list)), gamma)) - (np.power((counter2 / len(RM_list)), gamma)) \n",
    "        counter1 -= 1\n",
    "        counter2 -= 1\n",
    "        subj_ws_list.append(subj_ws)\n",
    "    subj_ws_list = subj_ws_list[::-1]\n",
    "    risk = (- np.matmul(np.transpose(RM_list), subj_ws_list))\n",
    "    print('|' + centered('Das Risiko beträgt: ' + str(risk) + '.') + '| ')\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prinzip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "# Delta\n",
    "\n",
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "gamma = 0.5\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################\n",
    "\n",
    "p = np.linspace(1/len(RM_list), len(RM_list)/len(RM_list), len(RM_list))\n",
    "phi = np.power(p, gamma)\n",
    "\n",
    "def make_delta_for_plot(liste, pop):\n",
    "    new_val = [val for val in liste for _ in (0, 1)]\n",
    "    if pop == -1:\n",
    "        new_val.pop(-1)\n",
    "    else:\n",
    "        new_val.pop(0)\n",
    "    return new_val\n",
    "\n",
    "new_x = make_delta_for_plot(p,pop=0)\n",
    "new_y = make_delta_for_plot(phi, pop=-1)\n",
    "\n",
    "plt.figure(figsize=(35,25)) \n",
    "plt.subplot(221)\n",
    "plt.plot(p, phi)\n",
    "plt.plot(new_x,new_y)\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('\\u03C6(p)')\n",
    "plt.title(' ')\n",
    "plt.grid()\n",
    "plt.axhline(0, color='black')\n",
    "plt.axvline(0, color='black')\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Fläche\n",
    "\n",
    "b = gamma\n",
    "p = np.array(np.arange(1/len(RM_list), len(RM_list)/len(RM_list), 1/len(RM_list)))\n",
    "phi_p = np.power((b * p), (b-1))\n",
    "x = np.array(np.arange(1/len(RM_list),len(RM_list)/len(RM_list),1/len(RM_list)))\n",
    "\n",
    "liste = []\n",
    "for i in phi_p:\n",
    "    liste.append(i)\n",
    "y = liste\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(p, phi_p, color='orange')\n",
    "plt.bar(x, liste, width=(1/253), edgecolor='black')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('\\u03A6(p)')\n",
    "plt.title(' ')\n",
    "easy_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterfestlegung und Aufruf der Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "alpha = 0.1\n",
    "VaR(alpha)\n",
    "\n",
    "alpha = 0.1\n",
    "CVaR(alpha)\n",
    "\n",
    "gamma = 0.5\n",
    "power(gamma)\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risikomaße schätzen - Varianz-Kovarianz-Methode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Risk und Conditional Value at Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Berechnung des Value at Risk für die Varianz-Kovarianz-Methode ist analog zu der bei der historischen Simulation.\n",
    "Der einzige Unterschied ist, dass hierbei auf die zuvor für die analytische Verteilungsfunktion generierten Werte zurückgegriffen wird.\n",
    "Für den Conditional Value at Risk gilt selbiges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_list = sorted(var_covar_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power-Spektrales Risikomaß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Power-Spektrale Risikomaß für die Varianz-Kovarianz-Methode wird grundsätzlich wie das bei der historischen Simulation berechnet, wobei jedoch anstelle der historischen Portfolio-Realisationen auf (0,1) standardnormalverteilte Variablen zurückgegriffen wird, welche anschließend erneut mit einer subjektiven Wahrscheinlichkeit multipliziert werden.\n",
    "Die jeweiligen Ergebnisse werden aufsummiert und bilden das Risiko der auf (0,1) standardisierten Normalverteilung, welche dann mit der aus den Daten geschätzten Standardabweichung des Portfolios multipliziert und mit dem geschätzten Erwartungswert des Portfolios addiert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(gamma):\n",
    "    global mu_PF\n",
    "    global std_PF\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Power-Spektrales Risikomaß bei der Varianz-Kovarianz-Methode:') + '| ')\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')\n",
    "    print('|' + centered('Der Erwartungswert beträgt: ' + str(mu_PF) + '.') + '| ')\n",
    "    print('|' + centered('Die Standardabweichung beträgt: ' + str(std_PF)+ '.') + '| ')\n",
    "\n",
    "    array = np.array(np.arange(0.0001, 1, 0.0001))\n",
    "    counter0 = 0\n",
    "    counter1 = len(array)-1\n",
    "    counter2 = len(array)-2\n",
    "    xq_list = []\n",
    "    \n",
    "    for i in range(0, len(array)):\n",
    "        p = array[counter0]\n",
    "        x = stats.norm.ppf(p, 0, 1)\n",
    "        q = (np.power(array[counter1], gamma)) - (np.power(array[counter2], gamma))\n",
    "        if counter0 == len(array)-1:\n",
    "            q = (np.power(array[counter1], gamma))\n",
    "        counter0 += 1\n",
    "        counter1 -= 1\n",
    "        counter2 -= 1\n",
    "        xq = x*q\n",
    "        xq_list.append(xq)\n",
    "    \n",
    "    risk_nv = np.sum(xq_list)\n",
    "    risk = (- mu_PF + std_PF * risk_nv)\n",
    "    print('|' + centered('Das Risiko beträgt: ' + str(risk) + '.') + '| ')\n",
    "    print('#--------------------------------------------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterfestlegung und Aufruf der Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "#-------------------------------------------------------------------------\n",
    "alpha = 0.1\n",
    "VaR(alpha)\n",
    "\n",
    "alpha = 0.1\n",
    "CVaR(alpha)\n",
    "\n",
    "gamma = 0.5\n",
    "power(gamma)\n",
    "#-------------------------------------------------------------------------\n",
    "##########################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
